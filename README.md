# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
- This dataset contains information related to a direct marketing campaign of a Portuguese banking institution and if their clients did subscribe for a term deposit.
We seek to predict if the client was subscribed for a- term deposit or not and classify the predictions based on clients' personal and financial information.

- The best performing model was a SoftVotingClassifier (VotingEnsemble), using MaxAbcScaler and a Gradient tree boosting algorithm implemented within an XGBoostClassifier, as it's well known for the efficiency to predict accuracies. 
This model has been chosen among several models based on the highest accuracy while tuning the hyperdrive parameters during the experiment.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

A general pipeline architecture explaining the workflow of using Azure SDK with HyperDrive parameterization:

![alt_text](SklearnPipelineArchitecture.PNG)

Getting good results or bad ones are always related to two important things when preparing our model: 

1 - **The dataset and the cleaning: We used a Cleaing function included in the Train.py Script. <br>
   - Get the dataset as a csv from a link using TabularDatasetFactory and convert it to a DataFrame using pandas to clean it.<br>
   - Convert the extracted data into a binary dataframe representation that will be used later with the LogisticRegression classifier. We used Get_dummies() for the string type columns and lambda expressions for bolean columns, and returned x_df and y_df to be used later within the experiment.<br>
   - We define
2- **The algorithm choice:** The choice of the algorithm used in your model must be based on the metrics you need to predict: continious or discret?<br>
Since we will be estimating if the client did subscribe or not to a deposit term, we applied Sklearn LogistigRegression classifier using the dataset we cleaned and splited to training/testing datasets using Sklearn function *train_test_split* 
 

**What are the benefits of the parameter sampler you chose?**

**What are the benefits of the early stopping policy you chose?**

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
