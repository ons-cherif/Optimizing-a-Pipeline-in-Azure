# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
- This dataset contains information related to a direct marketing campaign of a Portuguese banking institution and if their clients did subscribe for a term deposit.<br>
We seek to predict if clients are subscibed for a term deposit based on the provided personal and financial information.

- The best performing model is a SoftVotingClassifier (VotingEnsemble), containing MaxAbcScaler and XGBoostClassifier which implements the Gradient tree boosting algorithm_  well known for its efficiency to predict accuracies. 
This model has been chosen among several models based on the highest accuracy, while tuning the hyperdrive parameters during the experiment.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

Below a general pipeline architecture is provided to explain the workflow of using Azure SDK with HyperDrive parameterization:

![alt_text](SklearnPipelineArchitecture.PNG)

Getting good or bad results is related to how well prepared your model is? <br>
1 - **The dataset and the cleaning:** We used a Cleaning function included in the Train.py Script. <br>
   - Used the TabularDatasetFactory method to retrieve data from the specified path.<br>
   - Converted the extracted data into a Dataframe representation to be used later with the LogisticRegression classifier.<br>
We applied the _Sklearn get_dummies()_ method for a binary representation to use later.<br>
   - Specify a parameter sampler to use in the Hyperparameters to be used during the experiment. For this case, we will consider:<br>
      - The inverse of regularization strength _**C**_<br>
      - The maximum number of iterations taken for the solvers to converge _**max_iter**_ <br>
   - split data into training and testing sets, using Sklearn function  *train_test_split* .<br>
2- **The algorithm choice:** Choosing an algorithm for a model must base on the metrics you need to predict: Continuous or Discrete?<br>
Since we want to estimate if the client did or not subscribe to a deposit term account, we applied the _Sklearn LogistigRegression_ classifier taking as parameters: the cleaned then split dataset into a training/testing dataset using Sklearn function *train_test_split* 
 

**What are the benefits of the parameter sampler you chose?**

**What are the benefits of the early stopping policy you chose?**

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
